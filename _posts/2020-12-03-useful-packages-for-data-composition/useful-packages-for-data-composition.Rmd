---
title: "Useful packages for data simulation"
description: |
  We will explore the packages wakefield, rcorpora, charlatan, fabricatr, and GenOrd which can be helpful for data simulation.
author:
  - name: Richard Vogg
    url: https://github.com/richardvogg
date: 12-03-2020
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc-float: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE,echo=TRUE)
```

When we simulate data we can rely on the distribution functions like `rnorm`, `rexp` and `sample` from base R. However, we can also leverage the great work from authors of packages which were written to make the simulation process easier. In this blogpost I will explore some of them.

## Additional packages

Before starting with the simulation packages, we can load these two packages which will help with data transformation and visualization.
 
```{r}
library(dplyr)
library(ggplot2)
```


## wakefield

Looking for interesting packages around data simulation I stumbled across the {wakefield} package by [Tyler Rinker](https://twitter.com/tylerrinker). 

```{r}
library(wakefield)
```

Introduction can be found [here](https://github.com/trinker/wakefield).

```{r}
r_data_frame(
    n = 500,
    id,
    age,
    iq,
    height,
    died,
    animal,
    internet_browser,
    political
)

```

There are a lot of predefined variables that you can use. (Call `variables(type="matrix",ncols=5)` to see them.)

```{r, echo=FALSE}
variables(type="matrix",ncols=5)
```

Additionally, you can access the distribution functions easily and tweak parameters of the predefined functions.

```{r}
test <- r_data_frame(
    n = 500,
    id,
    age(x=18:50),
    `Reading(mins)` = rpois(lambda=20),
    income(digits=0)
)
```

```{r,echo=FALSE}
test
```


Looks too perfect? Include random missing values in columns 2 and 4:

```{r}
test <- test %>% r_na(cols=c(2,4),prob=0.3)
```

```{r,echo=FALSE}
test
```

### Series

{wakefield} allows us to create several variables which can be seen as a sequence, for example survey results.

```{r}
r_series(likert,j = 5,n=10,name="Question")
```

These can also be packaged inside a data frame, for example when simulating test results for students.

```{r}
r_data_frame(
  n=10,
  Student=id,
  age=rpois(14),
  r_series(grade,j=3,integer=TRUE,name="Test")
)
```

That is great but not very real, because the test results are completely independent from each other.
The `relate` parameter inside the `r_series` function helps to connect the results, and the format is `fM_sd`.

* f is one of (+,-,*,/)
* M is the mean value
* sd is the standard deviation of the mean value

Examples:
* `+3_1`: The test results get better on average 3 points with a standard deviation of 1.
* `*1.05_0.2`: The results get better on average 5% with a standard deviation of 0.2.

```{r}
r_data_frame(
  n=10,
  Student=id,
  age=rpois(14),
  r_series(grade,j=3,integer=TRUE,name="Test",relate="+3_1")
)
```

With this in mind, you can create customer balances over time very easily.

```{r}
balances <- r_data_frame(
  n=10,
  Client=name,
  age,
  r_series(income,j=12,name="Month",relate="*1.03_0.1")
)
```

This result is worth to be visualized. 

```{r}
balances %>%
  tidyr::pivot_longer(-c(1,2),names_to="Month") %>%
  mutate(Month=readr::parse_number(Month)) %>%
  ggplot(aes(x=Month,y=value))+geom_line()+facet_wrap(~Client,scales="free_y")

```

We can see that there are customers who had very positive balance development and others whose balances were fluctuating more or declining.
However, when we simulate a sufficiently large number of customers, we will observe that on average the increase each month will be the desired 3% with a standard deviation of 0.1.



## rcorpora

Check the github repository [here](https://github.com/gaborcsardi/rcorpora).

The rcorpora library has 293 collections of words that can be very helpful for data simulation.

```{r}
library(rcorpora)

length(corpora())
corpora()[sample(1:293,10)]
```

To view the words of one collection use the name in the `corpora()` function.

```{r}
corpora("foods/pizzaToppings")
```

Let see how we can use this in a simulated dataframe.

```{r}

tibble(
  first_name=corpora("humans/firstNames")$firstNames %>% sample(100,replace=TRUE),
  last_name=corpora("humans/lastNames")$lastNames %>% sample(100,replace=TRUE),
  self_description=corpora("humans/descriptions")$descriptions %>% sample(100,replace=TRUE),
  home_country=corpora("geography/countries")$countries %>% sample(100,replace=TRUE),
  favorite_pizza_topping=corpora("foods/pizzaToppings")$pizzaToppings %>% sample(100,replace=TRUE)
)

```

## charlatan

Similar to wakefield, charlatan has some out-of-the-box variables that can be used in your simulated data.

```{r}

library(charlatan)

ch_job(n=10)
```

You can even use get typical names or jobs for a given country. To see the available languages and countries type `charlatan::PersonProvider$new()$allowed_locales()`.

```{r}
ch_name(n=10,locale="de_DE")
```


```{r}
ch_phone_number(locale="de_DE",n=10)
```

A nice small application with fake locations and random R colors.


```{r}
locations <- data.frame(lon=ch_lon(n=10),lat=ch_lat(n=10),col=ch_color_name(n=10))

ggplot(locations)+
  borders("world")+
  geom_point(aes(x=lon,y=lat,col=col),size=3)+
  coord_quickmap()
```

## fabricatr

Easy creation of hierarchical data is possible with {fabricatr}.
In this example there are five families, each one has between 1 and 12 members. Each family member has between 1 and 5 accounts. With `add_level()` we can automatically produce a table that shows all accounts of all members in all families.

```{r}
library(fabricatr)

fabricate(
  family  = add_level(N = 5,
  n_members = sample(1:12, N, replace = TRUE,prob=12:1)),
  
  members  = add_level(N = n_members,
  n_accounts = sample(1:5,N,replace=TRUE,prob=(5:1)^2)),
  
  account = add_level(N = n_accounts)
  ) %>%
head(10)
```

Link levels. We can create 15 clients with their birth year and join year and some correlation between both variables.

```{r}
df <- fabricate(
  age = add_level(N=51, birth_year=1950:2000),
  tenure = add_level(N = 20, join_year=1991:2010, nest = FALSE),
  client = link_levels(N = 15, by = join(age, tenure, rho = 0.7))
)

df %>% select(client,birth_year,join_year)

```


### Ordered data

`fabricatr` has an amazing function to create ordered categorical data.

The function we need is `draw_ordered`. It internally simulates a numeric variable (`x`) and breaks them into predefined categories.

```{r}
draw_ordered(
  x = rnorm(10),
  breaks = c(-2,-1,0.8,2),
  break_labels = c("Very boring","Boring","OK","Interesting","Very Interesting")
)
```

Let's take a look at another example where we have two types of clients, gold clients that receive a yearly gift from the bank and standard clients that do not. How could we simulate their responses to a satisfaction survey?

```{r}
df <- fabricate(
  N = 100,
  gold_client_flag = draw_binary(prob = 0.3, N),
  satisfaction = draw_ordered(
    x = rnorm(N, mean = -0.4 + 1.2 * gold_client_flag),
    breaks = c(-1.5, -0.5, 0.5, 1.5),
    break_labels = c("Very Unsatisfied", "Unsatisfied", "Neutral",
                     "Satisfied", "Very Satisfied")
  )
)

```

```{r,echo=FALSE}
head(df)
```


We can summarize the results and see the differences between the two groups. Ideal data for teaching hypothesis testing.

```{r}
df %>% count(gold_client_flag,satisfaction) %>%
  tidyr::pivot_wider(id_cols=satisfaction,names_from="gold_client_flag",values_from="n")
```



### Time series

Example from [this article](https://declaredesign.org/r/fabricatr/articles/time_series.html).

This example contains the GDP of five countries over the course of five years.

```{r}
panel_units <- fabricate(
  countries = add_level(
    N = 5,
    base_gdp = runif(N, 15, 22),
    growth_units = runif(N, 0.2, 0.8),
    growth_error = runif(N, 0.1, 0.5)
  ),
  years = add_level(
    N = 5,
    ts_year = 0:4,
    gdp_measure = base_gdp + (ts_year * growth_units) + rnorm(N, sd=growth_error)
  )
)

panel_units
```

```{r,echo=FALSE}
ggplot(panel_units,aes(x=ts_year,y=gdp_measure,col=countries,group=countries))+geom_line(size=2)
```

We can take this to the next level and introduce some year specific information and then cross this with the country specific information. We just have to add one layer.

```{r}
panel_global_data <- fabricate(
  years = add_level(
    N = 5,
    ts_year = 0:4,
    year_shock = rnorm(N, 0, 0.5) #each year has a global trend
  ),
  countries = add_level(
    N = 5,
    base_gdp = runif(N, 15, 22),
    growth_units = runif(N, 0.2, 0.5), 
    growth_error = runif(N, 0.1, 0.5),
    nest = FALSE
  ),
  country_years = cross_levels(
    by = join(years, countries),
    gdp_measure = base_gdp + year_shock + (ts_year * growth_units) +
      rnorm(N, sd=growth_error)
  )
)
```

```{r,echo=FALSE}
ggplot(panel_global_data,aes(x=ts_year,y=gdp_measure,col=countries,group=countries))+geom_line(size=2)
```

## GenOrd

This package helps to create discrete random variables with prescribed correlation matrix and marginal distributions.

```{r}
library(GenOrd)


k <- 4 #number of random variables
marginal <- list(0.6, c(1/3,2/3), c(1/4,2/4,3/4), c(1/5,2/5,3/5,4/5))

```

Read the list as follows:
* We will create 4 random variables.
* The first variable will have two values: 60% of the data will be 1, 40% will be 2.
* The second variable will have three values, 1,2 and 3 with a probability of 33% each.
* etc...
* Each vector in this list refers to one variable, and we will see the cumulative probability for each value.


```{r}
corrcheck(marginal)
```

This function shows what are allowable ranges for the correlation matrix, given the input from the marginal distributions.


```{r}
Sigma <- matrix(c(1,0.5,0.4,0.3,
                  0.5,1,0.5,0.4,
                  0.4,0.5,1,0.5,
                  0.3,0.4,0.5,1),
                k, k, byrow=TRUE)

```

We will create 1000 observations, with the given correlation matrix. Each variable will have the marginal distribution described above.

```{r}

n <- 1000 # sample size
m <- ordsample(n, marginal, Sigma)

df <- data.frame(m)
head(df)
```

Let's verify that the data is actually what we expected. We check the correlation and the marginal distribution for two of the variables.

```{r}
cor(df)

df %>% count(X4)
df %>% count(X1)
```

Later we can rename the columns and values, but will have assured that they have the desired correlations.

## More packages

In this [blogpost](https://rviews.rstudio.com/2020/09/09/fake-data-with-r/) by Joseph Rickert on R Views.